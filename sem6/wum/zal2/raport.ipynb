{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71a0b99d",
   "metadata": {},
   "source": [
    "WUM - Zadanie 2\n",
    "Stanisław Bitner 438247"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69949f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.cluster.hierarchy import linkage, leaves_list\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict, cross_val_score, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Dropout\n",
    "from tensorflow.keras.regularizers import l1, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6198031",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_original = pd.read_csv('X_train.csv', sep=',')\n",
    "X_test_original = pd.read_csv('X_test.csv', sep=',')\n",
    "y_train_original = pd.read_csv('y_train.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dfc4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_original\n",
    "X_test = X_test_original\n",
    "\n",
    "y_train = y_train_original.drop(columns=['Id'])\n",
    "# Upewnij się, że y_train jest serią (Series), a nie DataFrame\n",
    "y_train = y_train.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693c0647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametry\n",
    "\n",
    "n_jobs = 8\n",
    "n_splits = 5 # Liczba podziałów w walidacji krzyżowej - standardowe 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=438247)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500e6cf9",
   "metadata": {},
   "source": [
    "# 1. Eksploracja (7 pkt.)\n",
    "## (a) \n",
    "Sprawdź, ile obserwacji i zmiennych zawierają wczytane dane treningowe oraz testowe. Przyj-\n",
    "rzyj się typom zmiennych i, jeśli uznasz to za słuszne, dokonaj odpowiedniej konwersji przed\n",
    "dalszą analizą. Upewnij się, czy dane są kompletne.\n",
    "## (b) \n",
    "Zbadaj rozkład empiryczny zmiennej objaśnianej (przedstaw kilka podstawowych statystyk,\n",
    "do analizy dołącz histogram lub wykres estymatora gęstości).\n",
    "## (c) \n",
    "Wybierz 250 zmiennych objaśniających najbardziej skorelowanych ze zmienną objaśnianą. Po-\n",
    "licz korelację dla każdej z par tych zmiennych. Zilustruj wynik za pomocą mapy ciepła (heat-\n",
    "map).\n",
    "\n",
    "Uwaga: opisany tu wybór zmiennych jest tylko na potrzeby niniejszego podpunktu, analizę\n",
    "opisaną w kolejnych zadaniach należy przeprowadzić na pełnym zbiorze danych treningowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117afd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdź liczbę obserwacji i zmiennych\n",
    "print(\"Liczba obserwacji i zmiennych w X_train:\")\n",
    "print(X_train.shape)\n",
    "print(\"Liczba obserwacji i zmiennych w X_test:\")\n",
    "print(X_test.shape)\n",
    "print(\"Liczba obserwacji i zmiennych w y_train:\")\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1479d38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przyjrzyj się typom zmiennych\n",
    "print(\"\\nTypy zmiennych w X_train:\")\n",
    "print(X_train.dtypes)\n",
    "print(\"\\nTypy zmiennych w X_test:\")\n",
    "print(X_test.dtypes)\n",
    "print(\"\\nTypy zmiennych w y_train:\")\n",
    "print(y_train.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ef5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdź kompletność danych\n",
    "print(\"\\nLiczba brakujących danych w X_train:\")\n",
    "print(X_train.isnull().sum())\n",
    "print(\"\\nLiczba brakujących danych w X_test:\")\n",
    "print(X_test.isnull().sum())\n",
    "print(\"\\nLiczba brakujących danych w y_train:\")\n",
    "print(y_train.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54198951-158f-4c5a-9813-156d3a9c365d",
   "metadata": {},
   "source": [
    "Wszystkie dane są typu float i są kompletne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a021edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oblicz podstawowe statystyki opisowe\n",
    "print(\"Podstawowe statystyki opisowe zmiennej objaśnianej (y_train):\")\n",
    "print(y_train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3686c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie histogramu\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(y_train, kde=False, bins=30)\n",
    "plt.title('Histogram zmiennej objaśnianej (y_train)')\n",
    "plt.xlabel('Wartość')\n",
    "plt.ylabel('Częstość')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7ae69c-33f7-4de0-a477-332105514eaa",
   "metadata": {},
   "source": [
    "Wykres pokazuje, że dane tworzą wykres zbliżony do normalnego z bardzo dużym dodatkiem zer.\n",
    "To oznacza, że można spodziewać się wielu zupełnie niepoprawnych predykcji -- model może na przykład przewidywać zawsze 0 i wciąż będzie miał całkiem dobrą dokładność, co oczywiście mija się z celem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766b4656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tworzenie wykresu estymatora gęstości\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(y_train.squeeze(), fill=True)\n",
    "plt.title('Estymator gęstości zmiennej objaśnianej (y_train)')\n",
    "plt.xlabel('Wartość')\n",
    "plt.ylabel('Gęstość')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134e9536",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations = X_train.corrwith(y_train, method='spearman').abs()\n",
    "top_features = correlations.sort_values(ascending=False).head(250).index\n",
    "X_top = X_train[top_features]\n",
    "corr_matrix = X_top.corr(method='spearman')\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm')\n",
    "plt.title('Mapa ciepła korelacji pomiędzy 250 najbardziej skorelowanymi zmiennymi objaśniającymi')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd3e0f0-1bf8-44bb-9294-40e0e801f4e7",
   "metadata": {},
   "source": [
    "Mapa ciepła dla korelacji Spearmana. Niestety niewiele można o niej powiedzieć, ze względu na dużą liczbę zmiennych.\n",
    "Wybrałem korelację Spearmana, gdyż korelacja Pearsona zakłada liniowość, której tu nie ma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dc3026",
   "metadata": {},
   "source": [
    "# 2. ElasticNet (7 pkt.)\n",
    "Pierwszy model, który należy wytrenować, to ElasticNet. Którego szczególne przypadki stanowią\n",
    "regresja grzbietowa (ridge regression) oraz lasso.\n",
    "## (a) \n",
    "Przedstaw w raporcie informacje o modelu ElasticNet, objaśniając parametry, które są w nim\n",
    "estymowane, optymalizowaną funkcję oraz hiperparametry, od których ona zależy. Dla jakich\n",
    "wartości hiperparametrów otrzymujemy regresję grzbietową, a dla jakich lasso?\n",
    "## (b) \n",
    "Zdefiniuj siatkę (grid ) hiperparametrów, opartą na co najmniej trzech wartościach każdego\n",
    "z hiperparametrów. Zadbaj o to, by w siatce znalazły się konfiguracje hiperparametrów od-\n",
    "powiadające regresji grzbietowej i lasso. Użyj walidacji krzyżowej do wybrania odpowiednich\n",
    "hiperparametrów (o liczbie podzbiorów użytych w walidacji krzyżowej należy zdecydować sa-\n",
    "modzielnie oraz uzasadnić swój wybór).\n",
    "## (c) \n",
    "Podaj błąd treningowy i walidacyjny modelu (należy uśrednić wynik względem wszystkich\n",
    "podzbiorów wyróżnionych w walidacji krzyżowej)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a22f9d",
   "metadata": {},
   "source": [
    "### Opis\n",
    "\n",
    "Wszystkie informacje pochodzą z tej strony - https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n",
    "\n",
    "1. Opis Modelu ElasticNet\n",
    "\n",
    "ElasticNet to liniowy model regresyjny, który łączy właściwości regresji grzbietowej (Ridge Regression) i Lasso (Least Absolute Shrinkage and Selection Operator). Główna zaleta ElasticNet polega na zdolności do jednoczesnego radzenia sobie z problemem wielokrotnej współliniowości (jak w Ridge Regression) oraz wykonywania selekcji cech (jak w Lasso).\n",
    "\n",
    "2. Parametry Estymowane przez ElasticNet\n",
    "\n",
    "- **Współczynniki regresji** (`coefficients`): Wagi przypisane każdej zmiennej objaśniającej, które są estymowane podczas trenowania modelu. Te wagi są interpretowane jako wpływ każdej zmiennej objaśniającej na zmienną objaśnianą.\n",
    "\n",
    "3. Optymalizowana Funkcja\n",
    "\n",
    "ElasticNet minimalizuje funkcję straty, która jest kombinacją sumy kwadratów reszt (RSS - Residual Sum of Squares) oraz regularizacji L1 i L2:\n",
    "\n",
    "$$\n",
    "\\text{Loss}(w, b) = \\frac{1}{2n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 + \\alpha \\left( \\rho \\sum_{j=1}^{p} |w_j| + \\frac{1 - \\rho}{2} \\sum_{j=1}^{p} w_j^2 \\right)\n",
    "$$\n",
    "\n",
    "gdzie:\n",
    "- $ y_i $ to rzeczywiste wartości.\n",
    "- $ \\hat{y}_i $ to przewidywane wartości.\n",
    "- $ w $ to wektory współczynników regresji.\n",
    "- $ b $ to wyraz wolny (intercept).\n",
    "- $ n $ to liczba próbek.\n",
    "- $ p $ to liczba zmiennych objaśniających.\n",
    "- $ \\alpha $ to parametr regularyzacji, który kontroluje siłę regularizacji.\n",
    "- $ \\rho $ to parametr balansujący między regularyzacją L1 a L2.\n",
    "\n",
    "4. Hiperparametry\n",
    "\n",
    "ElasticNet ma dwa główne hiperparametry:\n",
    "- **Alpha ($\\alpha$)**: Kontroluje siłę całkowitej regularizacji. Wysoka wartość \\(\\alpha\\) powoduje silniejszą regularizację, co może prowadzić do większego zredukowania współczynników.\n",
    "- **L1_ratio ($\\rho$)**: Kontroluje mieszankę regularyzacji L1 (Lasso) i L2 (Ridge). \\(\\rho\\) w zakresie od 0 do 1, gdzie:\n",
    "  - $\\rho = 1$: Model staje się Lasso, używając wyłącznie regularyzacji L1.\n",
    "  - $\\rho = 0$: Model staje się Ridge Regression, używając wyłącznie regularyzacji L2.\n",
    "  - $0 < \\rho < 1$: ElasticNet używa zarówno regularyzacji L1, jak i L2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b4f9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Definiowanie siatki hiperparametrów\n",
    "param_grid = {\n",
    "    'elasticnet__alpha': [0.1, 1.0, 10.0],\n",
    "    'elasticnet__l1_ratio': [0.0, 0.5, 1.0]\n",
    "}\n",
    "# ElasticNet wymaga standaryzacji zmiennych\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('elasticnet', ElasticNet())\n",
    "])\n",
    "# Użycie walidacji krzyżowej\n",
    "grid_search_en = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    n_jobs=n_jobs,\n",
    "    param_grid=param_grid,\n",
    "    cv=kf,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    return_train_score=True\n",
    ")\n",
    "grid_search_en.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5fd8fd",
   "metadata": {},
   "source": [
    "Jako wartości siatki parametrów wybrałem te najbardziej standardowe:\n",
    "- $\\alpha \\in \\{0, 1, 10\\}$;\n",
    "- $\\rho \\in \\{0, 0.5, 1\\}$.\n",
    " \n",
    "Oczywiście dla skrajnych wartości hiperparametrów otrzymujemy modele Ridge oraz Lasso.\n",
    "\n",
    "Walidację krzyżową przeprowadziłem 5-krotnie, co jest dobrym kompromisem między szybkością otrzymania danych, a także dokładnością wyniku.\n",
    "\n",
    "Ridge oraz Lasso wymagają, aby dane były ustandaryzowane, więc użyłem Pipeline'a, aby robił to sam używając StandardScalera. Skaler nie jest on idealny, a dane po zastosowaniu go wciąż pozostawiają wiele do życzenia, ale po konsultacji z Prowadzącą Laboratoria, nie było lepszych pomysłów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e2fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Najlepsze parametry i wynik\n",
    "best_params = grid_search_en.best_params_\n",
    "print(\"Najlepsze parametry: \", best_params)\n",
    "\n",
    "# Obliczenie średniego błędu treningowego i walidacyjnego\n",
    "cv_results_en = grid_search_en.cv_results_\n",
    "mean_train_rmse_en = -cv_results_en['mean_train_score'].mean()\n",
    "print(\"Średni błąd treningowy (RMSE): \", mean_train_rmse_en)\n",
    "mean_val_rmse_en = -cv_results_en['mean_test_score'].mean()\n",
    "print(\"Średni błąd walidacyjny (RMSE): \", mean_val_rmse_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eda7f8-f8c6-4081-a679-95fd30d3b0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Definiowanie siatki hiperparametrów\n",
    "param_grid = {\n",
    "    'model__alpha': [0.1, 1.0, 10.0],\n",
    "}\n",
    "# Ridge wymaga standaryzacji zmiennych\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', Ridge())\n",
    "])\n",
    "grid_search_ridge = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    cv=kf,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=n_jobs,\n",
    "    return_train_score=True\n",
    ")\n",
    "grid_search_ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298eb47-c4ec-4e32-9d79-1182f365ee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Najlepsze parametry i wynik\n",
    "best_params = grid_search_ridge.best_params_\n",
    "print(\"Najlepsze parametry: \", best_params)\n",
    "\n",
    "# Obliczenie średniego błędu treningowego i walidacyjnego\n",
    "cv_results_ridge = grid_search_ridge.cv_results_\n",
    "mean_train_rmse_ridge = -cv_results_ridge['mean_train_score'].mean()\n",
    "print(\"Średni błąd treningowy (RMSE): \", mean_train_rmse_ridge)\n",
    "mean_val_rmse_ridge = -cv_results_ridge['mean_test_score'].mean()\n",
    "print(\"Średni błąd walidacyjny (RMSE): \", mean_val_rmse_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace57cbe",
   "metadata": {},
   "source": [
    "Oprócz modelu ElasticNet, który ma problem z regresją grzbietową użyłem także modelu Ridge, który jest do niej stworzony i zoptymalizowany.\n",
    "Użycie go było również wspomniane w ostrzeżeniach jakie się pojawiały podczas wykonywania GridSearchCV na modelu ElasticNet.\n",
    "\n",
    "*Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.*\n",
    "\n",
    "Sam ElasticNet okazał się faworyzować Redge względem Lassa i optymalnymi parametrami okazały się $\\alpha=0.1, \\rho=0$, co jest równoważne regresji grzbietowej dla $\\alpha=0.1$. Sama regresja grzbietowa zachowywała się jednak najlepiej dla $\\alpha=10$.\n",
    "\n",
    "Ostatecznie oczywiście Ridge dał lepsze średnie RMSE ($0.44$) w porównaniu do ElasticNat-a ($0.69$), który do średniej wliczał również Lasso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8618bc",
   "metadata": {},
   "source": [
    "# 3. Lasy losowe (8 pkt.)\n",
    "W tej części projektu należy wytrenować model lasów losowych i porównać jego działanie z utwo-\n",
    "rzonym wcześniej modelem ElasticNet.\n",
    "## (a) \n",
    "Spośród wielu hiperparametrów charakteryzujących model lasów losowych wybierz trzy róż-\n",
    "ne. Zdefiniuj trójwymiarową siatkę przeszukiwanych kombinacji hiperparametrów i za pomocą\n",
    "walidacji krzyżowej wybierz ich optymalne (w kontekście wykonywanej predykcji) wartości.\n",
    "Wykorzystany przy walidacji krzyżowej podział danych powinien być taki sam, jak w przy-\n",
    "padku ElasticNet.\n",
    "## (b) \n",
    "Zrób podsumowanie tabelaryczne wyników, jakie otrzymywały metody w walidacji krzyżowej\n",
    "w obu rozważanych modelach. (Porównanie to jest powodem, dla którego zależy nam na zasto-\n",
    "sowaniu tych samych podziałów). Określ, który model wydaje Ci się najlepszy (uzasadnij swój\n",
    "wybór). Do porównania dołącz podstawowy model referencyjny, który dowolnym wartościom\n",
    "zmiennych objaśniających przypisuje średnią arytmetyczną zmiennej objaśnianej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f679f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Definiowanie siatki hiperparametrów\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 20, 50],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "# Użycie walidacji krzyżowej z 5 podzbiorami (5-fold cross-validation)\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(n_jobs=n_jobs),\n",
    "    n_jobs=n_jobs,\n",
    "    param_grid=param_grid,\n",
    "    cv=kf,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    return_train_score=True\n",
    ")\n",
    "# Dane mają gęstość ~10%, więc można zrobić csr_matrix\n",
    "grid_search_rf.fit(csr_matrix(X_train.values), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b354258d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Najlepsze parametry i wynik\n",
    "best_params = grid_search_rf.best_params_\n",
    "print(\"Najlepsze parametry: \", best_params)\n",
    "\n",
    "# Obliczenie średniego błędu treningowego i walidacyjnego\n",
    "cv_results_rf = grid_search_rf.cv_results_\n",
    "mean_val_rmse_rf = -cv_results_rf['mean_test_score'].mean()\n",
    "print(\"Średni błąd walidacyjny (RMSE): \", mean_val_rmse_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9248f8ba-c54a-4695-bf8e-82c57750dec5",
   "metadata": {},
   "source": [
    "Przede wszystkim, aby zoptymalizować wykonywanie się modelu, korzystając z niskiej gęstości danych (~10%), przerobiłem dane na csr_matrix, co zmniejszyło czasy wykonania około 4-krotnie.\n",
    "\n",
    "Wybrałem parametry *n_estimators* (liczba drzew w lesie), *max_depth* (maksymalna głębokość drzewa decyzyjnego)m *min_samples_split* (minimalna liczba próbek wymagana do podziału węzłów).\n",
    "\n",
    "Parametry te są standardowym wyborem.\n",
    "Wartości parametrów wybrałem takie, aby zachodził kompromis między biasem a wariancją modelu RandomForest oraz w celu zoptymalizowania jego dokładności i wydajności.\n",
    "\n",
    "Większa liczba drzew nie przynosiła wystarczająco dobrych rezultatów w porównaniu z czasem dopasowywania modelu do danych.\n",
    "Podobnie było z maksymalną głębokością drzew.\n",
    "\n",
    "Podobnie jak w przypadku ElasticNet, kroswalidacje wykonałem 5-krotnie, aby modele były lepiej porównywalne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59487ffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Błąd referencyjnego modelu (średni błąd na zbiorze treningowym)\n",
    "mean_val_rmse_ref = np.sqrt(np.mean((y_train - np.mean(y_train))**2))\n",
    "\n",
    "# Tabela z wynikami\n",
    "results_with_ref = [\n",
    "    [\"ElasticNet\",            mean_val_rmse_en],\n",
    "    [\"Ridge\",                 mean_val_rmse_ridge],\n",
    "    [\"RandomForestRegressor\", mean_val_rmse_rf],\n",
    "    [\"Referencyjny model\",    mean_val_rmse_ref]\n",
    "]\n",
    "\n",
    "# Tabela z wynikami z referencyjnym modelem\n",
    "print(tabulate(\n",
    "    results_with_ref,\n",
    "    headers=[\"Model\", \"Średni błąd walidacyjny (RMSE)\"],\n",
    "    tablefmt=\"fancy_grid\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660715ea",
   "metadata": {},
   "source": [
    "# TODO: opis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c9ecd9",
   "metadata": {},
   "source": [
    "# 4. Predykcja na zbiorze testowym (8 pkt.)\n",
    "Ta część projektu ma charakter otwarty. W oparciu o dane treningowe należy dopasować dowolnie\n",
    "wybrany model, a następnie zastosować go do przewidywania wartości zmiennej objaśnianej w\n",
    "zbiorze testowym. Sposób wyboru i budowy modelu, a także motywacje stojące za takim wyborem\n",
    "powinny zostać opisane w raporcie. Wygenerowane predykcje należy wysłać do prowadzącego w\n",
    "osobnym pliku, którego format został opisany wcześniej. Liczba uzyskanych punktów zależeć będzie\n",
    "od jakości predykcji, mierzonej pierwiastkiem błędu średniokwadratowego, RMSE.\n",
    "Szczegóły punktacji:\n",
    "* (1 pkt.) – za błąd niższy od pochodzącego z opisanego wcześniej, podstawowego modelu referencyj-\n",
    "nego.\n",
    "* (2 pkt.) – za błąd niższy od pochodzącego z modelu ElasticNet wytrenowanego przez prowadzących\n",
    "laboratoria.\n",
    "* (5 pkt.) – ten bonus obliczany jest według wzoru 12 ⌊10Fb(e)3 ⌋, gdzie e to błąd testowy predykcji studenta, Fb jest dystrybuantą empiryczną błędów wszystkich zgłoszonych predykcji w grupie laboratoryjnej studenta, natomiast ⌊·⌋ to część całkowita."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74ee1c1-4f3f-4192-9445-58e44f32b2a6",
   "metadata": {},
   "source": [
    "Ze względu na charakter danych ich normalizacja, czy też transformacja logarytmiczna psują je.\n",
    "To powoduje, że tak na prawdę zostajemy z dwiema możliwościami wyboru modelu: RandomForest i NeuralNetwork.\n",
    "\n",
    "Wybrałem sieć neuronową.\n",
    "\n",
    "Danych jest niecałem 4 tysiące, co jest dość niedużą liczbą. Najlepsze rezultaty sieci dawały dla od 512 do 4096 neuronów w każdej z ukrytych warstw. Liczba ukrytych warstw przy jakiej model zachowywał się sensownie i liczył w wystarczająco krótkim czasie, to od 3 do 5.\n",
    "\n",
    "Standardowo wybierałem losowo 80% danych jako treningowe i 20% jako walidacyjne.\n",
    "\n",
    "Z początku sprawdzałem 3 ukryte warstwy po 512 neuronów, każda z funkcją aktywacji ReLU.\n",
    "Dawało to wyniki podobne do modelu RandomForest z zadania 3-go.\n",
    "Aby wprowadzić nieliniowość zmieniłem funkcję aktywacji w środkowej warstwie na tanh, co przyniosło dobre efekty.\n",
    "\n",
    "Ostatecznie sprawdziłem ~50 modeli używających różnych funkcji aktywacji, przy czym w każdej używałem ReLU i tanh.\n",
    "Modele porównywałem na podstawie średniej wartości RMSE na walidacyjnych danych spośród 5 treningów.\n",
    "Najlepszym okazał się model zawierający 5 warstw ukrytych (512, gelu), (384, tanh), (4096, sigmoid), (384, gelu), (256, relu).\n",
    "Funkcja elu dawała bardzo duży rozrzut otrzymywanych błędów walidacyjnych, co oczywiście może skutkować słabymi wynikami na danych testowych, dlatego też ich nie używałem. Uznałem, że lepiej jest mieć model, który niezależnie od podziału danych daje podobne RMSE.\n",
    "Co ciekawe wstawienie sigmoida z bardzo dużą liczbą neuronów okazało się mieć pozytywny efekt na rmse dawane przez model.\n",
    "\n",
    "W rozwiązaniu sprawdzałem także zachowanie modelu, po dołożeniu warstw DropOut (około 0.3) i warstw BatchNormalization, jednak przyniosły one odwrotne do oczekiwanych skutki. Modele z tymi warstwami wykazywały tendencje, do znacznie gorszej predykcji, bez poprawy zjawisku overfittingu.\n",
    "\n",
    "Podobnie nieefektywny okazał się być EarlyStopping.\n",
    "\n",
    "Używanie regularyzacji l1 czy l2 nie przynosiło żadnych znaczących korzyści przy liczbie epok, na której trenowałem modele.\n",
    "\n",
    "Jeśli chodzi o BatchSize, to dobrym kompromisem między szybkością trenowania, a dokładnością predykcji okazał się rozmiar 64.\n",
    "Sprawdzałem również 16, 32 i 128, ale żaden z nich nie był zdecydowanie lepszy.\n",
    "\n",
    "Jedynym trikiem, który dał pozytywne efekty było dostosowanie LearningRate (do $0.001$), co nieznacznie poprawiło błędy walidacji.\n",
    "\n",
    "Liczba epok z jaką testowałem modele, to od 30 do 100, przy czym końcowy model ma ich 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955e16a0-be34-4d73-afce-280f8ecf32e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_original\n",
    "y_train = y_train_original.drop(columns=['Id'])\n",
    "y_train = y_train.squeeze()\n",
    "\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.2,\n",
    ")\n",
    "\n",
    "N = X_train.shape[1]\n",
    "model = Sequential([\n",
    "    Input(shape=(N,)),\n",
    "    Dense(512, activation='gelu'),\n",
    "    Dense(384, activation='tanh'),\n",
    "    Dense(4096, activation='sigmoid'),\n",
    "    Dense(384, activation='gelu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(1,   activation='linear')\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mean_squared_error'\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train_split, y_train_split,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_val_split, y_val_split),\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba6f52-eda1-4f2f-81f3-0a23ab00e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "val_rmse = np.sqrt(mean_squared_error(y_val_split, model.predict(X_val_split)))\n",
    "\n",
    "print(\"Błąd walidacyjny (RMSE): \", val_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc7fcff-6a40-46ab-b84f-bc4a2b173a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "ids = np.arange(len(X_test))\n",
    "df = pd.DataFrame({'Id': ids, 'Expected': predictions.flatten()})\n",
    "df.to_csv('sb438247_predykcja.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c2329-878a-4f7f-8cc7-79db60b95a23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
